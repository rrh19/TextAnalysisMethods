{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thread_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Muslims BUSTED: They Stole Millions In Gov’t B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Re: Why Did Attorney General Loretta Lynch Ple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BREAKING: Weiner Cooperating With FBI On Hilla...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hillary Goes Absolutely Berserk On Protester A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BREAKING! NYPD Ready To Make Arrests In Weiner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>WOW! WHISTLEBLOWER TELLS CHILLING STORY Of Mas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BREAKING: CLINTON CLEARED...Was This A Coordin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EVIL HILLARY SUPPORTERS Yell \"F*ck Trump\"…Burn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        thread_title\n",
       "0  Muslims BUSTED: They Stole Millions In Gov’t B...\n",
       "1  Re: Why Did Attorney General Loretta Lynch Ple...\n",
       "2  BREAKING: Weiner Cooperating With FBI On Hilla...\n",
       "3  PIN DROP SPEECH BY FATHER OF DAUGHTER Kidnappe...\n",
       "4  FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Heal...\n",
       "5  Hillary Goes Absolutely Berserk On Protester A...\n",
       "6  BREAKING! NYPD Ready To Make Arrests In Weiner...\n",
       "7  WOW! WHISTLEBLOWER TELLS CHILLING STORY Of Mas...\n",
       "8  BREAKING: CLINTON CLEARED...Was This A Coordin...\n",
       "9  EVIL HILLARY SUPPORTERS Yell \"F*ck Trump\"…Burn..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests \n",
    "import enchant\n",
    "\n",
    "frame = pd.read_csv(\"Desktop/FakeNews/fake.csv\")\n",
    "frame.drop(['uuid', 'ord_in_thread','published','language','crawled'], axis=1, inplace=True)\n",
    "df1 = frame.filter(items=['thread_title'])\n",
    "\n",
    "#this variable is a list of titles, but some of the titles are strings and some are \"nan\" values from the dataframe. \n",
    "#filter out of the nan values to get the code below to work\n",
    "df1 = df1.dropna() #filters out NaN values\n",
    "titles = list(df1['thread_title'])\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"\\ndef spellcheck(wordlist):\\n    result = []\\n    d = enchant.Dict(\"en_US\")\\n    for i in wordlist:\\n        if d.check(i) or d.check(i.capitalize()):\\n            result.append(i)    \\n    return result\\n\\ndef clean_text(list_of_texts):\\n    fully_cleaned =[]\\n    for i in list_of_texts:\\n        ocr_lower = i.lower()\\n        ocr_cleaner = ocr_lower.replace(\"\\n\", \" \").replace(\"\\t\", \" \")\\n        ocr_tokens = ocr_cleaner.split(\" \")\\n        no_numbers_or_punct = []\\n        for token in ocr_tokens:\\n            if token.isalpha():\\n                no_numbers_or_punct.append(token)\\n            else:\\n                new_token = \"\"\\n                for letter in token:\\n                    if letter.isalpha():\\n                        new_token += letter\\n                if new_token != \"\":\\n                    no_numbers_or_punct.append(new_token)  \\n        almost_ready_before_spellcheck = remove_stops(fullstops, no_numbers_or_punct)\\n        almost_ready = spellcheck(almost_ready_before_spellcheck)\\n        from nltk.stem import WordNetLemmatizer\\n        wordnet_lemmatizer = WordNetLemmatizer()\\n        lemmas = []\\n        for token in almost_ready:\\n            lemma = wordnet_lemmatizer.lemmatize(token)\\n            lemmas.append(lemma)\\n        ready = [i for i in lemmas if len(i) > 2]\\n        fully_cleaned.append(ready)\\n        fully_cleaned.append(no_numbers_or_punct)\\n    return fully_cleaned\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests \n",
    "import enchant\n",
    "\n",
    "frame = pd.read_csv(\"Desktop/FakeNews/fake.csv\")\n",
    "frame.drop(['uuid', 'ord_in_thread','published','language','crawled'], axis=1, inplace=True)\n",
    "df1 = frame.filter(items=['thread_title'])\n",
    "df1 = df1.dropna() #filters out NaN values\n",
    "titles = list(df1['thread_title'])\n",
    "# the above is the same as cell one\n",
    "\n",
    "#creating list of stopwords from multiple sources\n",
    "import nltk\n",
    "words = requests.get('http://ir.dcs.gla.ac.uk/resources/linguistic_utils/stop_words')\n",
    "stoplist1 = words.text.split(\"\\r\\n\")\n",
    "from nltk.corpus import stopwords\n",
    "stoplist2 = set(stopwords.words('english'))\n",
    "stoplist1.extend(stoplist2)\n",
    "fullstops = list(set(stoplist1))\n",
    "print(fullstops) #print to test success\n",
    "\n",
    "def split_titles(titlelist):\n",
    "    wordlist= []\n",
    "    for title in titlelist:\n",
    "        tokens = title.split(\" \")\n",
    "        for i in tokens:\n",
    "            wordlist.append(i)\n",
    "        \n",
    "split = split_titles(titles)\n",
    "print(split)\n",
    "\n",
    "def remove_stops(stoplist, wordlist):\n",
    "    result = []\n",
    "    for i in wordlist:\n",
    "        if i not in stoplist:\n",
    "                result.append(i)\n",
    "    return result\n",
    "\"\"\"\"\n",
    "def spellcheck(wordlist):\n",
    "    result = []\n",
    "    d = enchant.Dict(\"en_US\")\n",
    "    for i in wordlist:\n",
    "        if d.check(i) or d.check(i.capitalize()):\n",
    "            result.append(i)    \n",
    "    return result\n",
    "\n",
    "def clean_text(list_of_texts):\n",
    "    fully_cleaned =[]\n",
    "    for i in list_of_texts:\n",
    "        ocr_lower = i.lower()\n",
    "        ocr_cleaner = ocr_lower.replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n",
    "        ocr_tokens = ocr_cleaner.split(\" \")\n",
    "        no_numbers_or_punct = []\n",
    "        for token in ocr_tokens:\n",
    "            if token.isalpha():\n",
    "                no_numbers_or_punct.append(token)\n",
    "            else:\n",
    "                new_token = \"\"\n",
    "                for letter in token:\n",
    "                    if letter.isalpha():\n",
    "                        new_token += letter\n",
    "                if new_token != \"\":\n",
    "                    no_numbers_or_punct.append(new_token)  \n",
    "        almost_ready_before_spellcheck = remove_stops(fullstops, no_numbers_or_punct)\n",
    "        almost_ready = spellcheck(almost_ready_before_spellcheck)\n",
    "        from nltk.stem import WordNetLemmatizer\n",
    "        wordnet_lemmatizer = WordNetLemmatizer()\n",
    "        lemmas = []\n",
    "        for token in almost_ready:\n",
    "            lemma = wordnet_lemmatizer.lemmatize(token)\n",
    "            lemmas.append(lemma)\n",
    "        ready = [i for i in lemmas if len(i) > 2]\n",
    "        fully_cleaned.append(ready)\n",
    "        fully_cleaned.append(no_numbers_or_punct)\n",
    "    return fully_cleaned\n",
    "\"\"\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
